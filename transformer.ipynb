{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f4d8b1-ea5b-437c-890e-4a2b2f53ef8f",
   "metadata": {},
   "source": [
    "# Transformer Based Model for Chat-Bot\n",
    "Using Pytorch\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9cc9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c45c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 27 00:46:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P8              1W /   60W |    1969MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     12248    C+G   ....0_x64__8wekyb3d8bbwe\\XboxPcApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16508      C   ...0_x64__qbz5n2kfra8p0\\python3.10.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bb39cfa-baab-4126-97a5-1b874ad1fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b17eecd-c828-44f5-94c0-49e4a963ccf8",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fb879d7-e8af-4fce-9efc-64e25aed456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb469f5-8c11-4480-9c63-00a7677dc086",
   "metadata": {},
   "source": [
    "### Set Huperparameters for model\n",
    "\n",
    "- MAX_LEN = 40: The maximum length of input/output sequences (in tokens) for the model.\n",
    "- BATCH_SIZE = 64: The number of training samples processed in one forward/backward pass.\n",
    "- NUM_HEADS = 8: The number of attention heads in the multi-head attention mechanism.\n",
    "- D_MODEL = 512: The dimensionality of the modelâ€™s hidden layer representations.\n",
    "- FFN_UNITS = 2048: The number of units in the feed-forward neural network after each attention layer.\n",
    "- DROPOUT = 0.1: The fraction of units to drop during training to prevent overfitting.\n",
    "- NUM_LAYERS = 4: The number of layers in the encoder and decoder of the Transformer.\n",
    "- EPOCHS = 300: The number of full passes through the training dataset during training.\n",
    "- VOCAB_SIZE = 8000: The number of unique tokens in the model's vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ec4fa34-6cd2-4b58-9010-b4e896e5bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 40\n",
    "BATCH_SIZE = 64\n",
    "NUM_HEADS = 8\n",
    "D_MODEL = 512\n",
    "FFN_UNITS = 2048\n",
    "DROPOUT = 0.1\n",
    "NUM_LAYERS = 4\n",
    "EPOCHS = 110\n",
    "VOCAB_SIZE = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c119b9-6cb3-4d47-b7a3-e2483232fdf5",
   "metadata": {},
   "source": [
    "#### Setup decide for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f3ff5a6-c9cc-4305-8df8-5ce528c35eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ff2fe-40d5-4693-be1f-9f789d3120c8",
   "metadata": {},
   "source": [
    "#### load CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1aa6be1-6ad9-4829-a741-d1f87ed3a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'c:/Users/sabhi/Downloads/Cleaned_Wyckoff_QA_Dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data.columns = data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28efbbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Question', 'Answer']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74b1d25e-3a0c-42d0-be21-024dc61125ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data['Question'].astype(str).tolist()\n",
    "answers = data['Answer'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd17f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is an Upthrust (UT)?\n",
      "An Upthrust is a false breakout to the upside during distribution, designed to trap breakout traders before the price falls.\n"
     ]
    }
   ],
   "source": [
    "print(questions[1])\n",
    "print(answers[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61822ca-dee0-4cfe-b078-261e5bb22143",
   "metadata": {},
   "source": [
    "### Custom Tokenizer to keepp track of vocab and word to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9ebb63f-e9df-47df-b438-c25a72969c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self, vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word2idx = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2, \"<unk>\": 3}\n",
    "        self.idx2word = {0: \"<pad>\", 1: \"<start>\", 2: \"<end>\", 3: \"<unk>\"}\n",
    "        self.word_count = {}\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        for text in texts:\n",
    "            for word in text.split():\n",
    "                self.word_count[word] = self.word_count.get(word, 0) + 1\n",
    "        sorted_vocab = sorted(self.word_count.items(), key=lambda x: x[1], reverse=True)[:self.vocab_size - 4]\n",
    "        for idx, (word, _) in enumerate(sorted_vocab, start=4):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            seq = [self.word2idx.get(word, self.word2idx[\"<unk>\"]) for word in text.split()]\n",
    "            sequences.append(seq)\n",
    "        return sequences\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for seq in sequences:\n",
    "            text = \" \".join([self.idx2word.get(idx, \"<unk>\") for idx in seq])\n",
    "            texts.append(text)\n",
    "        return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af66fe89-0ec2-4986-8c24-18b4ed6218a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CustomTokenizer(VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(questions + answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb298b-77b0-4a5a-a305-2b0c701bdc65",
   "metadata": {},
   "source": [
    "### Initialize the dataset by converting the questions and answers to sequences of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19561f17-b729-4d70-b4d4-331871c1bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, questions, answers, tokenizer, max_len):\n",
    "        self.questions = tokenizer.texts_to_sequences(questions)\n",
    "        self.answers = tokenizer.texts_to_sequences(answers)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        answer = self.answers[idx]\n",
    "\n",
    "        question = [1] + question[:self.max_len - 2] + [2]\n",
    "        answer = [1] + answer[:self.max_len - 2] + [2]\n",
    "\n",
    "        question = question + [0] * (self.max_len - len(question))\n",
    "        answer = answer + [0] * (self.max_len - len(answer))\n",
    "\n",
    "        return torch.tensor(question), torch.tensor(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed96643-bc40-433e-a615-37fb540bef3d",
   "metadata": {},
   "source": [
    "### Compute the scaled dot-product attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6a51001-bcdc-4a28-bb1d-bc09d0bfc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
    "    dk = q.size(-1)\n",
    "    scaled_attention_logits = matmul_qk / torch.sqrt(torch.tensor(dk, dtype=torch.float32, device=q.device))\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    attention_weights = F.softmax(scaled_attention_logits, dim=-1)\n",
    "    output = torch.matmul(attention_weights, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5225062-e356-4a63-8bb7-ef9e7165c2a1",
   "metadata": {},
   "source": [
    "### Multi Head Atention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7004b140-c5f0-41e4-928f-cd912c579826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        batch_size = q.size(0)\n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "\n",
    "        attention = scaled_dot_product_attention(q, k, v, mask)\n",
    "        attention = attention.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.dense(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8dbfe-e06a-4af2-9858-339a50bdc8da",
   "metadata": {},
   "source": [
    "### Initialize the feed-forward network with two linear layers, ReLU activation, and dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9b3a10c-87c5-4d09-882c-8b8f35939c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, ffn_units, dropout_rate):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, ffn_units)\n",
    "        self.linear2 = nn.Linear(ffn_units, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.linear2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02458d2e-c74a-4c68-b617-9086758ca83a",
   "metadata": {},
   "source": [
    "### Encoder: Multi Head Attention with Layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ee82e1c-6f35-4f64-a1a2-b1c6f5a5afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ffn_units, dropout_rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(d_model, ffn_units, dropout_rate)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.attention(x, x, x, mask)\n",
    "        out1 = self.layernorm1(x + self.dropout(attn_output))\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + self.dropout(ffn_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2ec75-07ba-4a25-84a6-3188e4a0ded0",
   "metadata": {},
   "source": [
    "### Decoder: With look ahead mask and Cross attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4da4bee1-bfa6-42f0-8cda-27eef2fbca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ffn_units, dropout_rate):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.attention1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.attention2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(d_model, ffn_units, dropout_rate)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.layernorm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1 = self.attention1(x, x, x, look_ahead_mask)\n",
    "        out1 = self.layernorm1(x + self.dropout(attn1))\n",
    "\n",
    "        attn2 = self.attention2(out1, enc_output, enc_output, padding_mask)\n",
    "        out2 = self.layernorm2(out1 + self.dropout(attn2))\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        return self.layernorm3(out2 + self.dropout(ffn_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8c687f9-584b-452c-ac24-8e18d0df7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c916da2-e8c9-49db-a6f8-4ffea81973cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, ffn_units, num_layers, dropout_rate, max_len):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ffn_units, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ffn_units, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def create_look_ahead_mask(self, size):\n",
    "        mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
    "        return mask == 1\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input, encoder_mask=None, decoder_mask=None):\n",
    "        # Encoder\n",
    "        encoder_embedded = self.embedding(encoder_input)\n",
    "        encoder_embedded = self.positional_encoding(encoder_embedded)\n",
    "\n",
    "        encoder_output = encoder_embedded\n",
    "        for layer in self.encoder_layers:\n",
    "            encoder_output = layer(encoder_output, encoder_mask)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_embedded = self.embedding(decoder_input)\n",
    "        decoder_embedded = self.positional_encoding(decoder_embedded)\n",
    "\n",
    "        look_ahead_mask = self.create_look_ahead_mask(decoder_input.size(1)).to(decoder_input.device)\n",
    "\n",
    "        decoder_output = decoder_embedded\n",
    "        for layer in self.decoder_layers:\n",
    "            decoder_output = layer(decoder_output, encoder_output, look_ahead_mask, encoder_mask)\n",
    "\n",
    "        return self.fc(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a660e21b-fe89-4415-909d-e46a8bf51b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(VOCAB_SIZE, D_MODEL, NUM_HEADS, FFN_UNITS, NUM_LAYERS, DROPOUT, MAX_LEN)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e824dc40-c911-415e-8666-83dbc4195bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset(questions, answers, tokenizer, MAX_LEN)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8da8b2-9adb-4a14-b7b8-296f0b4c87aa",
   "metadata": {},
   "source": [
    "### Optimizer and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d70f6833-b434-4da7-bcda-47a6245c75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9ab5a-8f26-422e-8f5c-60d89e46af4e",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "177bc4f8-7e3c-4df0-9bcd-efff2ebf7fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110, Loss: 4.3153, Accuracy: 0.5216\n",
      "Epoch 2/110, Loss: 3.3063, Accuracy: 0.5690\n",
      "Epoch 3/110, Loss: 3.0019, Accuracy: 0.5889\n",
      "Epoch 4/110, Loss: 2.8196, Accuracy: 0.5959\n",
      "Epoch 5/110, Loss: 2.7036, Accuracy: 0.6048\n",
      "Epoch 6/110, Loss: 2.6044, Accuracy: 0.6143\n",
      "Epoch 7/110, Loss: 2.4919, Accuracy: 0.6254\n",
      "Epoch 8/110, Loss: 2.3878, Accuracy: 0.6333\n",
      "Epoch 9/110, Loss: 2.2898, Accuracy: 0.6414\n",
      "Epoch 10/110, Loss: 2.1843, Accuracy: 0.6520\n",
      "Epoch 11/110, Loss: 2.0985, Accuracy: 0.6637\n",
      "Epoch 12/110, Loss: 2.0063, Accuracy: 0.6741\n",
      "Epoch 13/110, Loss: 1.9251, Accuracy: 0.6849\n",
      "Epoch 14/110, Loss: 1.8394, Accuracy: 0.6964\n",
      "Epoch 15/110, Loss: 1.7626, Accuracy: 0.7051\n",
      "Epoch 16/110, Loss: 1.6848, Accuracy: 0.7151\n",
      "Epoch 17/110, Loss: 1.6059, Accuracy: 0.7235\n",
      "Epoch 18/110, Loss: 1.5341, Accuracy: 0.7341\n",
      "Epoch 19/110, Loss: 1.4580, Accuracy: 0.7426\n",
      "Epoch 20/110, Loss: 1.3835, Accuracy: 0.7523\n",
      "Epoch 21/110, Loss: 1.3189, Accuracy: 0.7609\n",
      "Epoch 22/110, Loss: 1.2410, Accuracy: 0.7723\n",
      "Epoch 23/110, Loss: 1.1764, Accuracy: 0.7819\n",
      "Epoch 24/110, Loss: 1.1082, Accuracy: 0.7931\n",
      "Epoch 25/110, Loss: 1.0410, Accuracy: 0.8049\n",
      "Epoch 26/110, Loss: 0.9761, Accuracy: 0.8174\n",
      "Epoch 27/110, Loss: 0.9141, Accuracy: 0.8309\n",
      "Epoch 28/110, Loss: 0.8529, Accuracy: 0.8431\n",
      "Epoch 29/110, Loss: 0.7921, Accuracy: 0.8574\n",
      "Epoch 30/110, Loss: 0.7326, Accuracy: 0.8714\n",
      "Epoch 31/110, Loss: 0.6789, Accuracy: 0.8847\n",
      "Epoch 32/110, Loss: 0.6296, Accuracy: 0.8975\n",
      "Epoch 33/110, Loss: 0.5762, Accuracy: 0.9111\n",
      "Epoch 34/110, Loss: 0.5266, Accuracy: 0.9246\n",
      "Epoch 35/110, Loss: 0.4819, Accuracy: 0.9362\n",
      "Epoch 36/110, Loss: 0.4398, Accuracy: 0.9457\n",
      "Epoch 37/110, Loss: 0.3988, Accuracy: 0.9568\n",
      "Epoch 38/110, Loss: 0.3605, Accuracy: 0.9653\n",
      "Epoch 39/110, Loss: 0.3245, Accuracy: 0.9730\n",
      "Epoch 40/110, Loss: 0.2933, Accuracy: 0.9790\n",
      "Epoch 41/110, Loss: 0.2632, Accuracy: 0.9836\n",
      "Epoch 42/110, Loss: 0.2364, Accuracy: 0.9878\n",
      "Epoch 43/110, Loss: 0.2119, Accuracy: 0.9908\n",
      "Epoch 44/110, Loss: 0.1898, Accuracy: 0.9932\n",
      "Epoch 45/110, Loss: 0.1697, Accuracy: 0.9954\n",
      "Epoch 46/110, Loss: 0.1530, Accuracy: 0.9968\n",
      "Epoch 47/110, Loss: 0.1378, Accuracy: 0.9976\n",
      "Epoch 48/110, Loss: 0.1222, Accuracy: 0.9982\n",
      "Epoch 49/110, Loss: 0.1103, Accuracy: 0.9987\n",
      "Epoch 50/110, Loss: 0.1006, Accuracy: 0.9987\n",
      "Epoch 51/110, Loss: 0.0911, Accuracy: 0.9994\n",
      "Epoch 52/110, Loss: 0.0825, Accuracy: 0.9992\n",
      "Epoch 53/110, Loss: 0.0756, Accuracy: 0.9994\n",
      "Epoch 54/110, Loss: 0.0696, Accuracy: 0.9995\n",
      "Epoch 55/110, Loss: 0.0638, Accuracy: 0.9996\n",
      "Epoch 56/110, Loss: 0.0591, Accuracy: 0.9994\n",
      "Epoch 57/110, Loss: 0.0545, Accuracy: 0.9996\n",
      "Epoch 58/110, Loss: 0.0509, Accuracy: 0.9997\n",
      "Epoch 59/110, Loss: 0.0475, Accuracy: 0.9996\n",
      "Epoch 60/110, Loss: 0.0442, Accuracy: 0.9997\n",
      "Epoch 61/110, Loss: 0.0413, Accuracy: 0.9997\n",
      "Epoch 62/110, Loss: 0.0391, Accuracy: 0.9998\n",
      "Epoch 63/110, Loss: 0.0369, Accuracy: 0.9997\n",
      "Epoch 64/110, Loss: 0.0345, Accuracy: 0.9997\n",
      "Epoch 65/110, Loss: 0.0326, Accuracy: 0.9998\n",
      "Epoch 66/110, Loss: 0.0311, Accuracy: 0.9996\n",
      "Epoch 67/110, Loss: 0.0292, Accuracy: 0.9997\n",
      "Epoch 68/110, Loss: 0.0275, Accuracy: 0.9997\n",
      "Epoch 69/110, Loss: 0.0263, Accuracy: 0.9999\n",
      "Epoch 70/110, Loss: 0.0251, Accuracy: 0.9998\n",
      "Epoch 71/110, Loss: 0.0239, Accuracy: 0.9998\n",
      "Epoch 72/110, Loss: 0.0229, Accuracy: 0.9998\n",
      "Epoch 73/110, Loss: 0.0220, Accuracy: 0.9997\n",
      "Epoch 74/110, Loss: 0.0211, Accuracy: 0.9997\n",
      "Epoch 75/110, Loss: 0.0204, Accuracy: 0.9998\n",
      "Epoch 76/110, Loss: 0.0193, Accuracy: 0.9998\n",
      "Epoch 77/110, Loss: 0.0187, Accuracy: 0.9998\n",
      "Epoch 78/110, Loss: 0.0178, Accuracy: 0.9998\n",
      "Epoch 79/110, Loss: 0.0173, Accuracy: 0.9997\n",
      "Epoch 80/110, Loss: 0.0166, Accuracy: 0.9997\n",
      "Epoch 81/110, Loss: 0.0162, Accuracy: 0.9998\n",
      "Epoch 82/110, Loss: 0.0156, Accuracy: 0.9997\n",
      "Epoch 83/110, Loss: 0.0149, Accuracy: 0.9998\n",
      "Epoch 84/110, Loss: 0.0145, Accuracy: 0.9998\n",
      "Epoch 85/110, Loss: 0.0139, Accuracy: 0.9998\n",
      "Epoch 86/110, Loss: 0.0137, Accuracy: 0.9997\n",
      "Epoch 87/110, Loss: 0.0132, Accuracy: 0.9998\n",
      "Epoch 88/110, Loss: 0.0126, Accuracy: 0.9998\n",
      "Epoch 89/110, Loss: 0.0123, Accuracy: 0.9997\n",
      "Epoch 90/110, Loss: 0.0118, Accuracy: 0.9998\n",
      "Epoch 91/110, Loss: 0.0115, Accuracy: 0.9998\n",
      "Epoch 92/110, Loss: 0.0111, Accuracy: 0.9998\n",
      "Epoch 93/110, Loss: 0.0109, Accuracy: 0.9999\n",
      "Epoch 94/110, Loss: 0.0106, Accuracy: 0.9998\n",
      "Epoch 95/110, Loss: 0.0105, Accuracy: 0.9998\n",
      "Epoch 96/110, Loss: 0.0106, Accuracy: 0.9998\n",
      "Epoch 97/110, Loss: 0.0100, Accuracy: 0.9998\n",
      "Epoch 98/110, Loss: 0.0107, Accuracy: 0.9997\n",
      "Epoch 99/110, Loss: 0.0102, Accuracy: 0.9997\n",
      "Epoch 100/110, Loss: 0.0104, Accuracy: 0.9996\n",
      "Epoch 101/110, Loss: 0.0103, Accuracy: 0.9997\n",
      "Epoch 102/110, Loss: 0.0095, Accuracy: 0.9997\n",
      "Epoch 103/110, Loss: 0.0091, Accuracy: 0.9998\n",
      "Epoch 104/110, Loss: 0.0085, Accuracy: 0.9998\n",
      "Epoch 105/110, Loss: 0.0082, Accuracy: 0.9998\n",
      "Epoch 106/110, Loss: 0.0078, Accuracy: 0.9998\n",
      "Epoch 107/110, Loss: 0.0076, Accuracy: 0.9998\n",
      "Epoch 108/110, Loss: 0.0074, Accuracy: 0.9998\n",
      "Epoch 109/110, Loss: 0.0072, Accuracy: 0.9998\n",
      "Epoch 110/110, Loss: 0.0070, Accuracy: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# Training Loop with Loss and Accuracy\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for questions_batch, answers_batch in dataloader:\n",
    "        questions_batch = questions_batch.to(device)\n",
    "        decoder_input = answers_batch[:, :-1].to(device)  # Input for decoder\n",
    "        target = answers_batch[:, 1:].to(device)  # Target for training\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(questions_batch, decoder_input)\n",
    "        loss = criterion(output.view(-1, VOCAB_SIZE), target.view(-1))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_tokens = torch.argmax(output, dim=-1)\n",
    "        correct_tokens = (predicted_tokens == target).sum().item()\n",
    "        total_accuracy += correct_tokens\n",
    "        total_tokens += target.numel()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_loss = total_loss / len(dataloader)\n",
    "    epoch_accuracy = total_accuracy / total_tokens\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b389d-7ea7-419f-ae58-98dff048e88f",
   "metadata": {},
   "source": [
    "### Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62ea317a-2071-404d-ac52-736e81aa201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'transformer_chatbot_gpu_deco_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655b734-09b0-49bc-a150-24fdeb13b25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f7c7476-7b2d-4e0c-892c-ae0dbfda7c01",
   "metadata": {},
   "source": [
    "### Load and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3a732d0-3507-426d-8e02-ef7e95b2e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: If price breaks below support, it quickly or breaks resistance to trap behavior.\n",
      "Bot: A failed rally during Distribution or price breaks key levels that quickly or strong supply has been absorbed.\n",
      "Bot: If buyers step in that the structure may signal in Accumulation or the CO may soon often a\n",
      "Bot: An upthrust breaks resistance and reverses on structure support with a structure precedes to trap\n",
      "Bot: This law states that price movement should be proportional to volume, a divergence signals a potential change.\n",
      "Bot: The Wyckoff Method is a technical analysis approach focused on identifying the intentions of large institutional investors through price and volume analysis.\n",
      "Bot: Accumulation is a phase where large players buy assets at low prices, absorbing supply before driving the price higher.\n",
      "Bot: If structure is unclear, tests fail repeatedly, and price movement suggests trend upward.\n",
      "Bot: If structure is unclear, tests fail repeatedly, and price movement suggests trend upward.\n",
      "Exiting chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Load the Trained Model\n",
    "model.load_state_dict(torch.load(\"transformer_chatbot_gpu_deco_1.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Chat Function\n",
    "def chat_response(question, tokenizer, model, max_len=40):\n",
    "    model.eval()\n",
    "    question_seq = tokenizer.texts_to_sequences([question])[0]\n",
    "    question_seq = [1] + question_seq[:max_len - 2] + [2]  # Add <start> and <end> tokens\n",
    "    question_seq = question_seq + [0] * (max_len - len(question_seq))  # Pad to max_len\n",
    "    question_tensor = torch.tensor([question_seq]).to(device)\n",
    "\n",
    "    decoder_input = torch.tensor([[1]]).to(device)  # Start token\n",
    "    response = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output = model(question_tensor, decoder_input)\n",
    "        predicted_id = torch.argmax(output[:, -1, :], dim=-1).item()\n",
    "        if predicted_id == 2:  # End token\n",
    "            break\n",
    "        response.append(predicted_id)\n",
    "        decoder_input = torch.cat([decoder_input, torch.tensor([[predicted_id]]).to(device)], dim=-1)\n",
    "\n",
    "    return tokenizer.sequences_to_texts([response])[0].replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
    "\n",
    "# Interactive Chat Loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting chatbot. Goodbye!\")\n",
    "        break\n",
    "    bot_response = chat_response(user_input, tokenizer, model)\n",
    "    print(f\"Bot: {bot_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c75c2-47dd-4313-b4ab-3173781bf9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
